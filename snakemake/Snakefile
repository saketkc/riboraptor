shell.executable("/bin/bash")
shell.prefix("source ~/.bashrc; ")

from collections import defaultdict
import os
import sys
import tempfile
from itertools import chain
from os.path import join
import glob
import re
import pandas as pd
import numpy as np
from snakemake.utils import report
from textwrap import dedent
import base64
from riboraptor.helpers import mkdir_p
from riboraptor.infer_protocol import infer_protocol
import h5py

ORIENTATIONS =['5prime', '3prime']
STRANDS = ['pos', 'neg', 'combined']# 'collapsed']
# collapsed strand = When we consider reads
# mapping only to strand where the gene is defined
FRAGMENT_LENGTHS = range(20, 51)

TMP_DIR_ROOT = None
INTRON_BED = None

include:
    config['config_path']

workdir: OUT_DIR

mkdir_p(join(OUT_DIR, 'slurm-logs'))
if not TMP_DIR_ROOT:
    TMP_DIR_ROOT = '/tmp'

if not INTRON_BED:
    INTRON_BED = CDS_BED.replace('cds', 'intron')

def total_genome_size():
    df = pd.read_table(CHROM_SIZES, names=['chrom', 'sizes'])
    total = df['sizes'].sum()
    return total


def get_align_intro_params():
    df = pd.read_table(INTRON_BED, names=['chrom', 'start', 'end', 'name', 'score', 'strand'])
    lengths = df['end'] - df['start']

    ## Based on small genomes. See https://groups.google.com/forum/#!topic/rna-star/hQeHTBbkc0c
    alignintronNmin = max(4, lengths.min())
    alignintronNmax = lengths.max()
    return alignintronNmin, alignintronNmax

ALIGN_INTRON_Nmin, ALIGN_INTRON_Nmax = get_align_intro_params()

TOTAL_GENOME_SIZE = total_genome_size()
## Small genome optimization
## See STAR manual 2.2.5
SA_INDEX_Nbases = int(np.floor(min(14, np.log2(TOTAL_GENOME_SIZE)/2.0-1)))

ALL_SRA_FILES = glob.glob('{}/**/*.sra'.format(RAWDATA_DIR), recursive=True)
SRX_ID_DICT = defaultdict(list)
for sample in ALL_SRA_FILES:
    srx, srr = sample.replace('{}'.format(RAWDATA_DIR),'').lstrip('/').rstrip('/').split('/')
    SRX_ID_DICT[srx].append(srr.replace('.sra', ''))
#print(SRX_ID_DICT)

SRX_ID_DICT_VALUES = list(SRX_ID_DICT.values())
SRX_SAMPLES = list(SRX_ID_DICT.keys())

ALL_SRR = [item for sublist in SRX_ID_DICT_VALUES for item in sublist]


def merge_bams_input(wildcards):
    return ['mapped/srr_bams/{}.bam'.format(srr) for srr in SRX_ID_DICT[wildcards.sample]]

def merge_fastq_input(wildcards):
    return ['sratofastq/{}.fastq.gz'.format(srr) for srr in SRX_ID_DICT[wildcards.sample]]

def sra_to_fastq_input(wildcards):
    srr_id = wildcards.sample
    for key in list(SRX_ID_DICT.keys()):
        value = SRX_ID_DICT[key]
        if srr_id in list(value):
            srx_id = key
            return str(os.path.join(RAWDATA_DIR, srx_id, srr_id+'.sra'))
    print("WRONG encodeterend: {}".format(srr_id))

rule all:
    input:
        #expand('mapped/plots/metagene/{sample}.png', sample=SRX_SAMPLES),
        #expand('mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/{orientation}_{strand}.bw',
        #        sample=SRX_SAMPLES,
        #        fragment_length=FRAGMENT_LENGTHS,
        #        orientation=ORIENTATIONS,
        #        strand=STRANDS),
        #expand('mapped/fragment_lengthwise_metagene_coverages/{sample}/{fragment_length}/{orientation}_{strand}.tsv',
        #        sample=SRX_SAMPLES,
        #        orientation=ORIENTATIONS,
        #        fragment_length=FRAGMENT_LENGTHS,
        #        strand=STRANDS),
        #expand('mapped/plots/fragment_lengthwise_metagene/{sample}/{fragment_length}/{orientation}_{strand}.png',
        #        sample=SRX_SAMPLES,
        #        fragment_length=FRAGMENT_LENGTHS,
        #        orientation=ORIENTATIONS,
        #        strand=STRANDS),
        expand('merged_fastq/{sample}.fastq.gz', sample=SRX_SAMPLES),
        expand('qc/{sample}_fastqc.html', sample=SRX_SAMPLES),
        'mapped/featureCounts/fcounts.tsv',
        'multiqc_report/multiqc_report.html',
        #expand('mapped/reports/{sample}_riboraptor_report.html', sample=SRX_SAMPLES),


rule sra_to_fastq:
    input: sra_to_fastq_input
    output: 'sratofastq/{sample}.fastq.gz'
    params:
        prefix='sratofastq/{sample}.fastq'
    shell:
        r'''fastq-dump --split-3 -O sratofastq {input} && gzip {params.prefix}
        '''

rule merge_fastq:
    input: merge_fastq_input
    output: 'merged_fastq/{sample}.fastq.gz'
    shell:
        r'''cat {input} > {output}
        '''

rule perform_qc:
    input:
        'merged_fastq/{sample}.fastq.gz'
    params:
        out_dir = 'qc'
    output:
       'qc/{sample}_fastqc.html',
       'qc/{sample}_fastqc.zip',
    resources:
        mem_mb=10000
    shell:
        r'''fastqc -o {params.out_dir} -f fastq {input}
        '''

rule perfom_trimming_merged:
    input:
        R1='merged_fastq/{sample}.fastq.gz',
    params:
        out_dir='merged_preprocessed/',
        phred_cutoff=5
    output:
        'merged_preprocessed/{sample}_trimmed.fq.gz'
    shell:
        r'''
        trim_galore -o {params.out_dir} -q {params.phred_cutoff} {input.R1}
        '''


rule perfom_trimming:
    input:
        R1='sratofastq/{sample}.fastq.gz',
    params:
        out_dir='preprocessed/',
        phred_cutoff=5
    output:
        'preprocessed/{sample}_trimmed.fq.gz'
    shell:
        r'''
        trim_galore -o {params.out_dir} -q {params.phred_cutoff} {input.R1}
        '''


rule map_star:
    input:
        R1='preprocessed/{sample}_trimmed.fq.gz',
        index=STAR_INDEX
    output:
        bam='mapped/srr_bams/{sample}.bam',
        txbam='mapped/srr_tx_bams/{sample}.bam',
        counts='mapped/STARcounts/{sample}.counts',
    params:
        name = '{sample}',
        prefix = 'mapped/srr_bams/{sample}',
        starlogs = 'mapped/starlogs',
    threads: 16
    run:
        with tempfile.TemporaryDirectory(dir=TMP_DIR_ROOT) as temp_dir:
            shell(r'''
                  STAR --runThreadN {threads}\
                       --genomeDir {input.index}\
                       --outFilterMismatchNmax 2\
                       --alignIntronMin {ALIGN_INTRON_Nmin}\
                       --alignIntronMax {ALIGN_INTRON_Nmax}\
                       --outFileNamePrefix {params.prefix}\
                       --readFilesIn {input.R1}\
                       --readFilesCommand zcat\
                       --quantMode TranscriptomeSAM GeneCounts\
                       --outSAMtype BAM Unsorted\
                       --outTmpDir {temp_dir}/{params.name}_tmp\
                       --outFilterType BySJout\
                       --outFilterMatchNmin 16\
                       --seedSearchStartLmax 15\
                       --winAnchorMultimapNmax 200\
                       --alignEndsType EndToEnd\
                       && samtools sort -@ {threads} {params.prefix}Aligned.out.bam -o {output.bam} -T {temp_dir}/{params.name}_sort\
                       && mv {params.prefix}Aligned.toTranscriptome.out.bam {output.txbam}\
                       && samtools index {output.bam}\
                       && mv {params.prefix}ReadsPerGene.out.tab {output.counts}\
                       && mkdir -p {params.starlogs}\
                       && mv {params.prefix}Log.final.out {params.prefix}Log.out {params.prefix}SJ.out.tab\
                       {params.prefix}Log.progress.out {params.starlogs}
                 ''')


rule merge_bams:
    input: merge_bams_input
    threads: 16
    output: 'mapped/bams/{sample}.bam'
    run:
        if len(input) > 1:
            with tempfile.TemporaryDirectory(dir=TMP_DIR_ROOT) as temp_dir:
                cmd = ' -in '.join(input)
                shell(r'''bamtools merge -in {cmd} -out {output}.unsorted \
                && samtools sort -@ {threads} -T {temp_dir}/{wildcards.sample}_merge_bam -o {output} {output}.unsorted \
                && samtools index {output} \
                && yes | rm -rf {output}.unsorted''')
        elif len(input) == 1:
            cmd = input[0]
            shell('''mv {cmd} {output} \
            && mv {cmd}.bai {output}.bai''')

rule extract_uniq_mapping:
    input: 'mapped/bams/{sample}.bam'
    output: 'mapped/bams_unique/{sample}.bam'
    threads: 16
    run:
        with tempfile.TemporaryDirectory(dir=TMP_DIR_ROOT) as temp_dir:
            shell(r'''
            samtools view -b -q 255 {input} -o {output}.temp \
            && samtools sort -@ {threads} {output}.temp -o {output} -T {temp_dir}/{wildcards.sample}_sort \
            && rm -rf {output}.temp \
            && samtools index {output}
            ''')



rule create_uniq_bedgraph_from_bam:
    input: 'mapped/bams_unique/{sample}.bam'
    output: 'mapped/bedGraphs/{sample}.bg'
    params:
    shell:
        r'''
        riboraptor bam-to-bedgraph --bam {input} \
        --end_type 5prime \
        --strand + \
        --saveto {output} \
        && bedSort {output} {output}
        '''

rule create_uniq_bigwig_from_uniq_bedgraph_raw:
    input: 'mapped/bedGraphs/{sample}.bg',
    output: 'mapped/bigWigs/{sample}.bw',
    shell:
        r'''bedGraphToBigWig {input} {CHROM_SIZES} {output}'''


rule export_utr5_coverage:
    input: 'mapped/bigWigs/{sample}.bw'
    params:
        offset_5p = 10
    output: 'mapped/gene_coverages/UTR5/{sample}_gene_coverages.tsv'
    shell: r'''riboraptor export-gene-coverages \
           --bw {input} \
           --bed {UTR5_BED} \
           --saveto {output} \
           --offset_5p {params.offset_5p}'''


rule export_cds_coverage:
    input: 'mapped/bigWigs/{sample}.bw'
    params:
        offset_5p = 10
    output: 'mapped/gene_coverages/CDS/{sample}_gene_coverages.tsv'
    shell: r'''riboraptor export-gene-coverages \
           --bw {input} \
           --bed {CDS_BED} \
           --saveto {output} \
           --offset_5p {params.offset_5p}'''


rule export_utr3_coverage:
    input: 'mapped/bigWigs/{sample}.bw'
    params:
        offset_5p = 10
    output: 'mapped/gene_coverages/UTR3/{sample}_gene_coverages.tsv'
    shell: r'''riboraptor export-gene-coverages \
           --bw {input} \
           --bed {UTR3_BED} \
           --saveto {output} \
           --offset_5p {params.offset_5p}'''


rule fragment_length_pickle:
    input: 'mapped/bams_unique/{sample}.bam'
    output: 'mapped/fragment_length_pickle/{sample}.tsv'
    shell:
        r'''riboraptor read-length-dist --bam {input} --saveto {output}'''


rule export_read_length:
    input: 'mapped/bams_unique/{sample}.bam'
    output: 'mapped/read_lengths/{sample}.tsv'
    shell:
        r'''
        riboraptor export-read-length --bam {input} --saveto {output}
        '''

rule plot_read_length:
    input: 'mapped/read_lengths/{sample}.tsv'
    output: 'mapped/plots/read_length/{sample}.png'
    shell:
        r'''
        riboraptor plot-read-length --millify_labels --read-lengths {input} --saveto {output}
        '''

rule export_metagene:
    input: 'mapped/bigWigs/{sample}.bw'
    output: 'mapped/metagene_coverages/{sample}.tsv'
    params:
        orientation = '5prime'
    shell:
        r'''
        riboraptor export-metagene-coverage --bw {input} \
        --bed {CDS_BED} --saveto {output} --orientation {params.orientation}
        '''


rule plot_metagene:
    input: 'mapped/metagene_coverages/{sample}.tsv'
    output: 'mapped/plots/metagene/{sample}.png'
    shell:
        r'''
        riboraptor plot-metagene --counts {input} --saveto {output} --positions -60:100
        '''

rule metagene_coverage_cds2:
    input: 'mapped/bams_unique/{sample}.bam'
    output: 'mapped/genewise_counts_CDS/{sample}.tsv'
    shell:
        r'''riboraptor count-reads-bed --bam {input} --bed {CDS_BED} --saveto {output}
        '''

rule infer_protocol:
    input: 'mapped/bams_unique/{sample}.bam'
    output: 'mapped/infer_protocol/{sample}.txt'
    shell: 
        r'''riboraptor infer-protocol --bam {input} --refseq {GENE_BED} > {output}

        '''

rule create_hdf:
    input: 'mapped/bams_unique/{sample}.bam'
    output:
        hdf = 'mapped/hdf/{sample}.hdf5',
        tsv = 'mapped/hdf/{sample}.tsv',
    params:
        prefix = 'mapped/hdf/{sample}'
    shell:
        r'''riboraptor bam-coverage --bam {input} --genebed {GENE_BED} --outprefix {params.prefix}
        '''

rule hdf_to_bw:
    input: 'mapped/hdf/{sample}.hdf5'
    output:
        prime5_pos = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/5prime_pos.bw',
        prime3_pos = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/3prime_pos.bw',
        prime5_neg = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/5prime_neg.bw',
        prime3_neg = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/3prime_neg.bw',
        prime5_combined = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/5prime_combined.bw',
        prime3_combined = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/3prime_combined.bw',
    params:
        prefix = 'mapped/fragment_lengthwise_bigwigs/{sample}',
        readlength = '{fragment_length}'
    shell:
        r'''riboraptor hdf-to-bw --hdf {input} --prefix {params.prefix} --readlength {params.readlength} && touch {output}'''


rule export_metagene_individual:
    input: 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/{orientation}_{strand}.bw'
    output: 'mapped/fragment_lengthwise_metagene_coverages/{sample}/{fragment_length}/{orientation}_{strand}.tsv'
    params:
        orientation = '{orientation}'
    shell:
        r'''
        riboraptor export-metagene-coverage --bw {input} --bed {CDS_BED} --orientation {params.orientation} --saveto {output} --offset_5p 60 --offset_3p 60
        '''

rule plot_metagene_individual_length:
    input: 'mapped/fragment_lengthwise_metagene_coverages/{sample}/{fragment_length}/{orientation}_{strand}.tsv'
    output: 'mapped/plots/fragment_lengthwise_metagene/{sample}/{fragment_length}/{orientation}_{strand}.png'
    run:
        if wildcards.orientation == '5prime':
            range = '-60:100'
        else:
            range = '-100:60'
        shell(r'''riboraptor plot-metagene --counts {input} --saveto {output} --positions {range}''')

rule report:
    input:
      metagene = 'mapped/plots/metagene/{sample}.png',
      prime5_pos = 'mapped/plots/fragment_lengthwise_metagene/{sample}/{fragment_length}/5prime_pos.png',
      prime3_pos = 'mapped/plots/fragment_lengthwise_metagene/{sample}/{fragment_length}/3prime_pos.png',
      prime5_neg = 'mapped/plots/fragment_lengthwise_metagene/{sample}/{fragment_length}/5prime_neg.png',
      prime3_neg = 'mapped/plots/fragment_lengthwise_metagene/{sample}/{fragment_length}/3prime_neg.png',
      prime5_combined = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/5prime_combined.png',
      prime3_combined = 'mapped/fragment_lengthwise_bigwigs/{sample}/{fragment_length}/3prime_combined.png',
      fragment_length = 'mapped/plots/read_length/{sample}.png',
    output:
        html='mapped/reports/{sample}_riboraptor_report.html'
    run:
        text = dedent("""
        <html>
        <center>
        <h1> Sample: {sample} </h1>
        <h1> Fragment Length Distribution </h1>


        """)

        for m in input.fragment_length:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))

            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))

        text += dedent('''

        <h1> Metagene Plots (5' positive strand)</h1>

                ''')
        for m in input.prime5_pos:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))

            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))
        for m in input.prime3_pos:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))

            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))
        for m in input.prime5_neg:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))

            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))
        for m in input.prime3_neg:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))

            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))

        for m in input.prime5_combined:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))

            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))

        for m in input.prime3_combined:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))

            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))

        for m in input.m:
            with open(m, 'rb') as f:
                encoded = base64.b64encode(f.read())
            img_tag = '<img alt="" src="data:image/png;base64,{0}" height="400px">'.format(str((encoded), 'utf-8'))
            fragment_l = m.split('_')[-1].replace('.png', '')
            text += dedent('''
            <figure>
            {img_tag}
            <figcaption> {fig_name}-{fragment_l} </figcaption>
            </figure>''').format(img_tag=img_tag, fig_name=m.split('/')[-1].replace('.png', ''))


        text += dedent("""
        </center>
        </html>
        """)
        #report(text=text, path=output.html, **input)
        with open(output.html, 'w') as f:
            f.write(text)

rule featurecounts:
    input:
        bams = expand('mapped/bams/{sample}.bam', sample=SRX_SAMPLES),
        hdfs = expand('mapped/hdf/{sample}.hdf5', sample=SRX_SAMPLES)
    params:
        annotation=GTF
    output: 'mapped/featureCounts/fcounts.tsv'
    threads: 16
    run:
        protocols = []
        for i in input.hdfs:
            hdf = h5py.File(i, 'r')
            protocol = hdf.attrs['protocol']
            protocols.append(protocol)
        assert len(set(protocols)) == 1
        protocol = protocols[0]
        if protocol == 'forward':
            count_strat = '-s 1'
        elif protocol == 'unstranded':
            count_strat = '-s 2'
        else:
            count_strat = ''
        shell(r'''featureCounts {count_strat} -a {params.annotation} -o {output} -t exon -g gene_id -Q 4 -T {threads} {input.bams}''')


rule run_multiqc:
    input:
        fastqc = expand('qc/{sample}_fastqc.html', sample=SRX_SAMPLES),
        trimmed = expand('merged_preprocessed/{sample}_trimmed.fq.gz', sample=SRX_SAMPLES),
        bams = expand('mapped/bams/{sample}.bam', sample=SRX_SAMPLES),
        counts = 'mapped/featureCounts/fcounts.tsv',
    output:
        'multiqc_report/multiqc_report.html'
    resources:
        mem_mb=10000
    shell:
        r'''
            multiqc qc merged_preprocessed mapped/bams mapped/featureCounts -f --outdir multiqc_report .
        '''
